{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hamna/miniconda3/envs/loggpt/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    HfArgumentParser,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    "    logging\n",
    ")\n",
    "from peft import LoraConfig, PeftModel\n",
    "from trl import SFTTrainer\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Follow-Up Prompt Format 3.2 3b-instruct model chat template\n",
    "\n",
    "To render the following as a block of text, use triple backticks and write it as code:\n",
    "\n",
    "```python\n",
    "follow_up_prompt = (\n",
    "    \"<|begin_of_text|>\"                              # start of prompt\n",
    "    \"<|start_header_id|>user<|end_header_id|>\"        # past  \n",
    "    f\"{question}\"                                     # past\n",
    "    \"<|eot_id|>\"                                      # past\n",
    "    \"<|start_header_id|>assistant<|end_header_id|>\"   # past\n",
    "    f\"{response}\"                                     # past\n",
    "    \"<|eot_id|>\"                                      # past\n",
    "    \"<|start_header_id|>user<|end_header_id|>\"       # new\n",
    "    f\"{follow_up_question}\"                          # new\n",
    "    \"<|eot_id|>\"                                     # new\n",
    "    \"<|start_header_id|>assistant<|end_header_id|>\"  # new\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>questions</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What are the four main variants of the A320 fa...</td>\n",
       "      <td>The four main variants are A318, A319, A320, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the common fuselage design feature of ...</td>\n",
       "      <td>They share a standard six-abreast economy clas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How many seats can the A320 family accommodate?</td>\n",
       "      <td>The A320 family can accommodate between 107 an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How does the A321’s seating capacity compare t...</td>\n",
       "      <td>The A321 has five more seats than the 737-900ER.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the width of the seats in the A320 fam...</td>\n",
       "      <td>The A320 family offers seats that are 1 inch w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           questions  \\\n",
       "0  What are the four main variants of the A320 fa...   \n",
       "1  What is the common fuselage design feature of ...   \n",
       "2    How many seats can the A320 family accommodate?   \n",
       "3  How does the A321’s seating capacity compare t...   \n",
       "4  What is the width of the seats in the A320 fam...   \n",
       "\n",
       "                                             answers  \n",
       "0  The four main variants are A318, A319, A320, a...  \n",
       "1  They share a standard six-abreast economy clas...  \n",
       "2  The A320 family can accommodate between 107 an...  \n",
       "3   The A321 has five more seats than the 737-900ER.  \n",
       "4  The A320 family offers seats that are 1 inch w...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('qa_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = '/home/hamna/llama/3.2_3b_instruct'\n",
    "\n",
    "new_model = 'llama_32_3b_instruct_finetune_40_EPOCHS_1'\n",
    "\n",
    "output_dir = '/media/hamna/New Volume/pdf_fine_tune_llama_work/model_fine_tune_qa_hamna_dataset'\n",
    "\n",
    "lora_r = 64\n",
    "\n",
    "lora_alpha = 16\n",
    "\n",
    "lora_dropout = 0.1\n",
    "\n",
    "use_4bit = True\n",
    "\n",
    "bnb_4bit_compute_dtype = 'float16'\n",
    "\n",
    "bnb_4bit_quant_type = 'nf4'\n",
    "\n",
    "use_nested_quant = False\n",
    "\n",
    "################################################################################\n",
    "# TrainingArguments parameters\n",
    "################################################################################\n",
    "\n",
    "output = './results_40_epochs'\n",
    "\n",
    "num_train_epochs = 40\n",
    "\n",
    "fp16 = False\n",
    "bf16 = False\n",
    "\n",
    "per_device_train_batch_size = 4\n",
    "\n",
    "per_device_eval_batch_size = 4\n",
    "\n",
    "# Number of update steps to accumulate the gradients for\n",
    "gradient_accumulation_steps = 1\n",
    "\n",
    "gradient_checkpointing = True\n",
    "\n",
    "max_grad_norm = 0.3 \n",
    "\n",
    "learning_rate = 2e-4\n",
    "\n",
    "weight_decay = 0.001\n",
    "\n",
    "optim = 'paged_adamw_32bit'\n",
    "\n",
    "lr_scheduler_type = \"cosine\"\n",
    "\n",
    "max_steps =  -1\n",
    "\n",
    "warmup_ratio = 0.03\n",
    "\n",
    "group_by_length = True\n",
    "\n",
    "save_steps = 0\n",
    "\n",
    "logging_steps = 25\n",
    "\n",
    "################################################################################\n",
    "# SFT parameters\n",
    "################################################################################\n",
    "\n",
    "max_seq_length = None\n",
    "\n",
    "packing = False \n",
    "\n",
    "device_map = {\"\": 0}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========\n",
      " Your GPU supports bfloat16: accelearate training with bf16=True\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.10s/it]\n"
     ]
    }
   ],
   "source": [
    "compute_dtype = getattr(torch, bnb_4bit_compute_dtype)\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit = use_4bit,\n",
    "    bnb_4bit_quant_type = bnb_4bit_quant_type,\n",
    "    bnb_4bit_computer_dtype = compute_dtype,\n",
    "    bnb_4bit_use_double_quant = use_nested_quant\n",
    ")\n",
    "\n",
    "if compute_dtype == torch.float16 and use_4bit:\n",
    "    major, _ = torch.cuda.get_device_capability()\n",
    "    if major >= 8:\n",
    "        print(\"=\" * 8)\n",
    "        print(\" Your GPU supports bfloat16: accelearate training with bf16=True\")\n",
    "        print(\"=\" * 80)\n",
    "\n",
    "#Loading the base Model\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config  =  bnb_config,\n",
    "    device_map = device_map\n",
    ")\n",
    "\n",
    "model.config.use_cache = False\n",
    "model.config.pretraining_tp = 1\n",
    "\n",
    "#Now Loading the Llama Model architecture Tokenizier\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 225/225 [00:00<00:00, 6343.47 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Load the training dataset\n",
    "dataset = load_dataset(\"csv\", data_files=\"qa_data.csv\", split=\"train\")\n",
    "# dataset = load_dataset(dataset, split=\"train\")\n",
    "\n",
    "# Define a function to apply the chat template\n",
    "def apply_chat_template(example):\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": example['questions']},\n",
    "        {\"role\": \"assistant\", \"content\": example['answers']}\n",
    "    ]\n",
    "    prompt = tokenizer.apply_chat_template(\n",
    "        messages, tokenize=False, add_generation_prompt=True\n",
    "    )\n",
    "    return {\"prompt\": prompt}\n",
    "\n",
    "# Apply the chat template function to the dataset\n",
    "new_dataset = dataset.map(apply_chat_template)\n",
    "new_dataset = new_dataset.train_test_split(0.1, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['questions', 'answers', 'prompt'],\n",
       "        num_rows: 202\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['questions', 'answers', 'prompt'],\n",
       "        num_rows: 23\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = new_dataset['train']\n",
    "test_dataset = new_dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['questions', 'answers', 'prompt'],\n",
       "    num_rows: 202\n",
       "})"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['How are A checks structured under Revision 28 of the A320’s MPD?',\n",
       " 'What is the estimated current market value (CMV) of a 1988 A320-200 powered by CFM56-5A?',\n",
       " 'Which engine variant has historically had higher sales in the A320 family?',\n",
       " 'Which airlines have selected the common CFM56-5B series engine?',\n",
       " 'How many A319 aircraft does United Airlines operate?',\n",
       " 'What is the purpose of the Tech Insertion package for the CFM56-5B?',\n",
       " 'What is the main purpose of the structural modifications in ATA chapter 53?',\n",
       " 'How many total pre-flight checks are assumed to be performed annually?',\n",
       " 'How does improving fault detection affect flight delays?',\n",
       " 'What engine variant powers the majority of the A319 fleet?',\n",
       " 'How are heavy components categorized in A320 maintenance?',\n",
       " 'What engine was developed by International Aero Engines (IAE) for the A320-200?',\n",
       " 'What thrust rating was first offered on the A320 in the mid-1990s?',\n",
       " 'What percentage of the A320 family fleet is made up of the A320 and A319 models?',\n",
       " 'How much additional fuel does the A319 burn compared to the A321 per passenger?',\n",
       " 'What is the maximum range achievable with supplementary fuel tanks in the A320?',\n",
       " 'What is the principal variant of the A320 family?',\n",
       " 'What engine thrust variants are available for the A320 family?',\n",
       " 'What is the total cost for materials and component repairs during C checks?',\n",
       " 'What is the fuel capacity of the A319 in the study?',\n",
       " 'How does headwind affect fuel burn during flights?',\n",
       " 'What are the benefits of using high-rated engines on the A320 family?',\n",
       " 'How many aircraft does Air Canada operate with the -5A1 engines?',\n",
       " 'What is the range of the V.2500-powered A320-200?',\n",
       " 'What are the largest operators of the V.2527-A5 engines?',\n",
       " 'What factors influence the actual price paid for new A320s?',\n",
       " 'What tool does Airbus provide for analyzing fault codes?',\n",
       " 'What has been the reliability trend for the IAE V.2500-A1 engines?',\n",
       " 'What is the impact of the A320 family’s production volume on its market activity?',\n",
       " 'How many A319s have been ordered with V.2500 engines?',\n",
       " 'What engines are available for the A318?',\n",
       " 'What is the typical seating configuration for the A320 in a two-class layout?',\n",
       " 'What is the CMV of a 1994 A319?',\n",
       " 'How many aircraft are powered by the -5B6 variant?',\n",
       " 'What impact did the bankruptcy of Northwest Airlines have on the A320 family market?',\n",
       " 'What effect does a 60-knot headwind have on the flight from Munich to London?',\n",
       " 'What factor contributes to the lower costs of the A320 maintenance cycle?',\n",
       " 'What will be the impact of the Tech Insertion package on maintenance costs?',\n",
       " 'Why have values and lease rates for the A320 family aircraft strengthened recently?',\n",
       " 'What is the width of the seats in the A320 family compared to its competitors?',\n",
       " 'How many daily checks are estimated to be performed annually?',\n",
       " 'How does engine rating affect fuel burn?',\n",
       " 'What are the key advantages of the A320 family’s commonality concept?',\n",
       " 'What is the initial process for clearing technical defects in the A320?',\n",
       " 'How much can an average airline credit expect to negotiate for leasing a half-life, IAE-powered A320-200?',\n",
       " 'Which CFM56 models are most common in the A319 fleet?',\n",
       " \"How does the A318's order performance compare to the 737-600?\",\n",
       " 'How many firm orders has the A319 received since its launch?',\n",
       " 'What thrust rating did the V.2500-A1 have for take-off in hot and high conditions?',\n",
       " 'What is the purpose of the Centralized Fault Display System (CFDS)?',\n",
       " 'How many aircraft have been delivered from the A320 family by the time of the report?',\n",
       " 'What maintenance task consumes the most MH during A checks?',\n",
       " 'How many seats can the A320 family accommodate?',\n",
       " 'What is the range of the A320 with the V.2527-A5 engine?',\n",
       " 'What was the production increase to keep up with A320 family demand?',\n",
       " 'How many A319s are on order as of the report?',\n",
       " 'What is the main function of the airworthiness directive (AD) number 99-13-01 for the V2500-A5 engine?',\n",
       " 'Which engines are offered for the A319?',\n",
       " 'What factors contributed to the A320 family’s success?',\n",
       " 'How many A320s powered by the V.2500 have been ordered?',\n",
       " 'What was the A320 family’s most successful year for orders?',\n",
       " 'What is the benefit of the onboard fault detection system?',\n",
       " 'What is the maximum take-off weight (MTOW) of the first V.2500-powered A320-200?',\n",
       " 'What is the monthly rental range for a 1996, half-life A320 on a five-year lease?',\n",
       " 'What engines power the A318 aircraft?',\n",
       " 'What is the maximum take-off weight (MTOW) of the A320-100?',\n",
       " 'How much does it cost for materials and consumables per A check?',\n",
       " 'How many A checks are typically performed each year?',\n",
       " 'How many passengers were analyzed on the A319 during the fuel burn study?',\n",
       " 'What are the four main variants of the A320 family?',\n",
       " 'What type of checks can flightcrew perform on the A320?',\n",
       " 'What is the main appeal of the A320 family to airlines?',\n",
       " 'How much is the estimated cost for freighter conversion of an A320?',\n",
       " 'Who was the first customer to place an order for the A320?',\n",
       " 'What must be installed for the A320 to be converted into a freighter?',\n",
       " 'How many firm orders has the A318 received?',\n",
       " 'What does the V.2500Select modification package offer?',\n",
       " 'What is the range of the A321 with CFM56-5B engines for the 83.0 tonne variant?',\n",
       " 'What has been the trend in lease rates for older A320-200s since 2005?',\n",
       " 'What advantage does the V.2500 engine have in terms of fuel efficiency?',\n",
       " 'How often are weekly checks performed compared to the MPD interval?',\n",
       " 'How often do operators perform A checks on the A320?',\n",
       " 'How far can the A320-100 fly with a load of 164 passengers?',\n",
       " 'What was the first A321 variant delivered, and when?',\n",
       " 'Where are ECAM messages displayed?',\n",
       " 'How do operating weights affect fuel consumption in the study?',\n",
       " 'How many orders did the V.2524-A5 receive for the A319?',\n",
       " 'What was the average weight used for each passenger in the fuel burn study?',\n",
       " 'What is the primary feature of the A320 family’s flight control system?',\n",
       " 'Which airlines operate multiple variants of the A320 family?',\n",
       " 'How many A320 family aircraft have been ordered with CFM56 engines?',\n",
       " 'What is the seating capacity of the A318?',\n",
       " 'What is the estimated total cost for daily checks per year?',\n",
       " 'What MTOWs were analyzed for the A320?',\n",
       " 'What is the total annual cost for A checks?',\n",
       " 'How much more fuel does the CFM56-5B4 burn compared to the V.2527-A5 on the A320?',\n",
       " 'How many TR checks are assumed to be performed each year?',\n",
       " 'What engines were initially used in the A320-100 model?',\n",
       " 'How are fault messages transmitted to maintenance control?',\n",
       " 'What is the tracked distance for the London to Munich flight?',\n",
       " 'How many A319 aircraft have been ordered with CFM56 engines?',\n",
       " 'What is the main challenge for launching a freighter conversion program for the A320?',\n",
       " 'How are technical defects logged by the flightcrew?',\n",
       " 'How many modifications are identified in ATA chapter 55 regarding the stabilizer?',\n",
       " 'What is the typical flight time from London to Munich under the studied conditions?',\n",
       " 'Which airline discovered issues with the in-board flap trunnion wear?',\n",
       " 'Which airline operates the largest fleet of -5B5 powered A319s?',\n",
       " 'What operational benefit does the common engine type provide to airlines?',\n",
       " 'What is the range of the higher gross weight A319 variant with supplementary fuel tanks?',\n",
       " 'Which system is being retrofitted to the more recent H2-F2 standard?',\n",
       " 'Which airline has ordered 15 PW6124 powered A318s?',\n",
       " 'What is the thrust rating of the CFM56-5A3 engine?',\n",
       " 'What is the estimated annual cost for materials used during pre-flight checks?',\n",
       " 'What distinguishes the A318 from its competitors?',\n",
       " 'What modifications were introduced to address corrosion in the A320 wings?',\n",
       " 'How many aircraft are powered by the PW6000 engines in the A320 family?',\n",
       " \"How does the A320's onboard system assist with fault detection?\",\n",
       " 'What is the maximum gross weight of the highest MTOW variant of the A320?',\n",
       " 'Which engine variants power the A320 family?',\n",
       " 'What is the estimated MH consumption for a weekly check?',\n",
       " 'Which airlines operate the largest fleets of CFM56-5A1-powered A320s?',\n",
       " 'What additional costs are associated with C checks on the A320?',\n",
       " 'When will the Tech Insertion specification become the production build standard for the -5B?',\n",
       " 'Which airline has the largest fleet of V.2500-A1 engines?',\n",
       " 'What is the estimated MH consumption for A checks?',\n",
       " 'How many A319s, A320s, and A321s are currently listed in storage by Airclaims?',\n",
       " 'What factors contribute to the large number of airframe-engine combinations in the A320 family?',\n",
       " 'What is the average lifespan for the high-pressure compressor LLPs in CFM56-5B engines?',\n",
       " 'What modifications address the detection of cracks in the A320 elevators?',\n",
       " 'What replaced many older aircraft types in the A320 family’s market?',\n",
       " 'What is the estimated man-hour (MH) expenditure for pre-flight checks per year?',\n",
       " 'What is the maximum seating capacity of the A320 in an all-economy layout?',\n",
       " 'What was a key finding from the structural checks on the A320 wings?',\n",
       " 'What is the CMV for a 2003 A318?',\n",
       " 'What is the average MH used for a typical turnaround (TR) check?',\n",
       " 'What are the largest customers of the A320?',\n",
       " 'What is the common fuselage design feature of the A320 family?',\n",
       " 'What is the seating capacity of the A319 in a two-class configuration?',\n",
       " 'What is the total number of orders for the V.2522-A5?',\n",
       " 'What is the extended range of the A320-200 variant?',\n",
       " 'What is the reserve cost per engine flight hour (EFH) for the CFM56-5B powering the A320?',\n",
       " 'How does the A320 family compare to the 737NG in terms of orders?',\n",
       " \"How does the A319's sales volume compare to the 727-200 and 737-300?\",\n",
       " 'How much can a 2005 A321-200 realize in lease rates today?',\n",
       " 'How many A321 aircraft are equipped with CFM56-5B1 engines?',\n",
       " 'What was the order status for engines outstanding in late 2005?',\n",
       " 'How does the A320’s centralized fault display system (CFDS) function?',\n",
       " 'What thrust ratings does the CFM56-5B offer on the A320?',\n",
       " 'What are the CMV ranges for mid-production A320s from 1996-1998?',\n",
       " 'What major issue was discovered in the main landing gear (MLG) shock absorber?',\n",
       " 'How much can a 2000 A319 expect to lease for?',\n",
       " 'What is the fuel capacity of the initial A320 model, the A320-100?',\n",
       " 'What is the approximate fuel capacity of the A321 analyzed in the study?',\n",
       " 'What are the gross weight options for the A319?',\n",
       " 'What is the average time consumed for routine TR checks on the A320?',\n",
       " 'What is the estimated MH consumption for daily checks?',\n",
       " 'How many firm orders did the A320 receive by the end of 2005?',\n",
       " 'What is the current backlog of A320 family orders?',\n",
       " 'What is the estimated labor cost for A checks annually?',\n",
       " 'What are the three MTOW variants of the A320?',\n",
       " 'How many A320 family aircraft were ordered in 2005?',\n",
       " 'What is the purpose of the electronic centralized aircraft monitor (ECAM)?',\n",
       " 'What is the MTOW of the A320-200 model?',\n",
       " 'What is the estimated CMV for a 2005 A319?',\n",
       " 'What was the first aircraft of the A320 family?',\n",
       " 'How does the V.2500Select modification respond to market demands?',\n",
       " 'How much more fuel does the CFM56-5B6 burn compared to the V.2524-A5 on the A319?',\n",
       " 'What thrust ratings are available in the V.2500-A5 series?',\n",
       " 'What is the fuel capacity of the A320-200?',\n",
       " 'What engines can the A319 utilize?',\n",
       " 'How are shop visit costs structured for the CFM56-5B engines?',\n",
       " 'What does rotable support involve for A320 operators?',\n",
       " 'When was the A321 variant developed?',\n",
       " 'How did the V.2500-A5 series differ from the -A1 series?',\n",
       " 'What engines power the A320 family aircraft?',\n",
       " 'What is the standard two-class seat capacity of the A321?',\n",
       " 'Who placed the largest order for A319 aircraft?',\n",
       " 'What sales trend is observed for the A318 variant?',\n",
       " 'What engines are available for the A318?',\n",
       " 'What type of pilot rating do A320 family variants share?',\n",
       " 'What modifications does Airbus offer for the ADIRU?',\n",
       " 'How much does a brand-new A320 typically lease for today?',\n",
       " 'Which engine on the A320 had the highest fuel burn?',\n",
       " 'What are the intervals for replacing life-limited parts (LLPs) in the CFM56-5B engines?',\n",
       " 'What thrust ratings are available for the V.2500-A5 engines on the A321?',\n",
       " 'Which engine model powers the majority of the A320 family?',\n",
       " 'What can the supplementary fuel tanks increase the total capacity to?',\n",
       " 'What modification allowed the CFM56-5B series to provide higher thrust?',\n",
       " 'What contributed to the increase in availability of A320 family aircraft?',\n",
       " 'How many A320s are powered by CFM56-5B4 engines?',\n",
       " 'How many A319s powered by the V.2522-A5 have been built?',\n",
       " 'What are the main thrust ratings for the CFM56-5B engines?',\n",
       " 'How does the fuel burn of the A321 compare to the A319?',\n",
       " 'What is the current market value of a 1997, early-production A321-200?',\n",
       " 'How many A320-100 series aircraft were ordered?',\n",
       " 'What is the effect of increasing gross weight on fuel burn for similar engine types?',\n",
       " 'How often are TR checks typically performed for the A320?',\n",
       " 'How many MTOW variants are available for the A321?',\n",
       " 'Which engines power the A320 family?',\n",
       " 'What is the estimated annual cost for pre-flight checks on the A320?',\n",
       " 'How does the maintenance cost differ for the CFM56-5B and V.2500-A5 engines?',\n",
       " 'Which engine type on the A319 burns the least fuel according to the analysis?']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset['questions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A checks are grouped as a generic check and typically performed every 450 FH.',\n",
       " 'The CMV is approximately $13.5 million.',\n",
       " 'CFM56-powered A320s have historically outsold those powered by V.2500 engines.',\n",
       " 'Air France and Iberia use the CFM56-5B across all four A320 family variants.',\n",
       " 'United Airlines operates 78 A319 aircraft.',\n",
       " 'To improve fuel burn, increase durability, and enhance exhaust gas temperature (EGT) margin.',\n",
       " 'To address cracks and fatigue issues around rivets and fittings in the fuselage and landing gear areas.',\n",
       " 'Approximately 355 pre-flight checks.',\n",
       " 'It allows line mechanics to prepare in advance, reducing scheduled gate time and minimizing delays.',\n",
       " 'The -5B5 variant powers the majority of the A319 fleet.',\n",
       " 'Heavy components are categorized into wheels, tyres, brakes, landing gears, thrust reversers, and the APU.',\n",
       " 'The V.2500-A1 engine was developed for the A320-200.',\n",
       " 'The CFM56-5B4 engine rated at 27,000 lbs thrust.',\n",
       " 'The A320 and A319 account for 85% of all aircraft sold.',\n",
       " 'About 1.5 US gallons more per passenger.',\n",
       " 'The maximum range is extended to 3,050 nm.',\n",
       " 'The principal variant is the A320.',\n",
       " 'The available engine thrust variants are -5B4 (27,000 lbs), -5B5 (22,000 lbs), and -5B6 (23,500 lbs).',\n",
       " 'The total for materials and component repairs during C checks is estimated at $360,000-395,000.',\n",
       " '6,300 US gallons.',\n",
       " 'Headwinds increase tracked distance and flight time, which can lead to increased fuel consumption.',\n",
       " 'High-rated engines provide better field performance but result in higher fuel burn.',\n",
       " 'Air Canada operates 35 aircraft with -5A1 engines.',\n",
       " 'The range is 2,600 nautical miles (nm).',\n",
       " 'Major operators include jetBlue (82), United (97), and America West (38).',\n",
       " 'Factors include after-sales support, airframe and engine warranties, and manufacturer-customer relationships.',\n",
       " 'AIRMAN, a computerized tool for troubleshooting and fault isolation.',\n",
       " 'The reliability has improved, with MTBRs reaching 12,000-14,000 FH, and even up to 17,000 FH for some aircraft.',\n",
       " 'The large production volume ensures a constant market activity with aircraft continually being leased and placed.',\n",
       " 'The V.2500 has been selected for 395 A319s.',\n",
       " 'The A318 utilizes the CFM56-5B series and the PW6000 series.',\n",
       " 'The A320 typically has 12 first-class and 138 economy seats.',\n",
       " 'The CMV for the oldest A319s built in 1994 will be around $16 million.',\n",
       " 'The -5B6 variant powers 188 aircraft.',\n",
       " 'It created a surplus of at least 10 A319s and three A320s, which were rejected leases and parked.',\n",
       " 'It increases the tracked distance to 628 nautical miles and flight time to 90-92 minutes.',\n",
       " 'Reductions in MH used for modifications and non-routine tasks contribute to lower maintenance costs.',\n",
       " 'It is expected to reduce maintenance costs by 5%.',\n",
       " 'The availability of A320 family aircraft has dried up, leading to increased demand in a strong market.',\n",
       " 'The A320 family offers seats that are 1 inch wider than those in the 737/757 rivals.',\n",
       " 'Approximately 250 daily checks are expected to be performed each year.',\n",
       " 'Higher-rated engines provide better field performance but result in higher fuel burn.',\n",
       " 'Advantages include cross-crew qualification, single type rating, and shared components.',\n",
       " 'The process starts with logging and troubleshooting, followed by either clearing or deferring the defects.',\n",
       " 'They can negotiate a rental of $155,000-$179,000 for a five-year lease.',\n",
       " 'The -5B5 and -5B6 models dominate the A319 fleet.',\n",
       " \"The A318's performance, while disappointing, still exceeds that of the 737-600.\",\n",
       " 'The A319 has received 1,239 firm orders since its launch.',\n",
       " 'The V.2500-A1 had a thrust rating of 26,500 lbs.',\n",
       " \"To receive system failure messages from aircraft components' built-in test equipment (BITE) and display them on the ECAM.\",\n",
       " 'More than 2,600 aircraft have been delivered.',\n",
       " 'Routine tasks typically consume 80 MH.',\n",
       " 'The A320 family can accommodate between 107 and 185 seats.',\n",
       " 'The range is 2,870 nm with a standard fuel capacity of 6,300 USG.',\n",
       " 'Airbus increased production to 32 units per month, or 384 per year.',\n",
       " 'A total of 492 A319s are on order.',\n",
       " 'To mandate a borescope inspection for oil or heat damage in the high-pressure turbine (HPT) hardware.',\n",
       " 'CFM56-5B5, V.2522-A5, and V.2524-A5.',\n",
       " 'Factors include cabin comfort, operating efficiency, and commonality among variants.',\n",
       " 'The V.2500 has been chosen for 1,071 A320s to date.',\n",
       " 'The most successful year was 2005, with 918 orders.',\n",
       " 'It reduces time spent analyzing faults and minimizes maintenance hours on non-routine tasks.',\n",
       " 'The MTOW is 162,040 lbs (73.5 tonnes).',\n",
       " 'The rental range is $225,000-$249,000.',\n",
       " 'The A318 is powered by CFM56-5B8 and PW6124 engines.',\n",
       " 'The MTOW is 145,504 lbs.',\n",
       " 'Between $5,000 and $6,000 per check.',\n",
       " 'About six to seven A checks.',\n",
       " '124 passengers.',\n",
       " 'The four main variants are A318, A319, A320, and A321.',\n",
       " 'Pre-flight (PF) and transit checks.',\n",
       " 'The family concept allows for operational flexibility and cost efficiency.',\n",
       " 'Between $3.5 and $4.0 million.',\n",
       " 'Air France signed a letter of intent for 25 aircraft in 1981.',\n",
       " 'A side door, along with other modifications like strengthening the floor and installing smoke detection systems.',\n",
       " 'The A318 has received 97 firm orders.',\n",
       " 'Up to 1% fuel burn improvement and a 20-30% reduction in maintenance costs.',\n",
       " 'The range is 2,200 nm with a standard fuel capacity of 6,260 USG.',\n",
       " 'Lease rates for older A320-200s have strengthened by at least $30,000 a month.',\n",
       " 'It is generally the most fuel-efficient engine type across various A320 models.',\n",
       " \"Weekly checks are often performed every six to seven days instead of the MPD's eight-day interval.\",\n",
       " 'Operators typically perform six to seven A checks each year.',\n",
       " 'It has a range of about 1,800 nautical miles (nm).',\n",
       " 'The first A321 variant delivered was the A321-100 in 1994.',\n",
       " 'On the electronic centralized aircraft monitor in the flight deck.',\n",
       " 'Aircraft with the same actual take-off weight can have similar fuel consumption despite different MTOW ratings.',\n",
       " 'The V.2524-A5 has 113 orders for the A319.',\n",
       " '220 lbs.',\n",
       " 'The A320 family features a fly-by-wire (FBW) flight control system.',\n",
       " 'Airlines like Air France and British Airways operate multiple variants.',\n",
       " 'The CFM56 has powered 2,111 of the A320 family aircraft ordered.',\n",
       " 'The A318 has a two-class seating capacity of 107 seats.',\n",
       " 'The total annual cost for daily checks is about $125,000 for materials and $90,000 for labor.',\n",
       " '166,450lbs (75.5 tonnes) and 169,800lbs (77 tonnes).',\n",
       " 'About $77,000.',\n",
       " '6.1-6.5% more fuel.',\n",
       " 'About 1,480 TR checks.',\n",
       " 'The A320-100 had CFM56-5A1 engines.',\n",
       " 'Through the Aircraft Communication and Reporting System (ACARS).',\n",
       " '536 nautical miles.',\n",
       " 'The CFM56 has been selected for 700 A319 aircraft.',\n",
       " 'Ensuring there are enough customers and a large enough supply of economically attractive airframes.',\n",
       " 'Flightcrew log ECAM messages in the post-flight technical log, which are automatically recorded by the CFDIU.',\n",
       " 'Two modifications related to water ingress issues.',\n",
       " '78-80 minutes when flying south.',\n",
       " 'Lufthansa.',\n",
       " 'easyJet operates the largest fleet of -5B5 powered A319s with 58 aircraft.',\n",
       " 'It allows for operational flexibility and reduces engine inventory costs.',\n",
       " 'The extended range is 3,450 nm with a fuel capacity of 7,070 USG.',\n",
       " 'The flight warning computer (FWC).',\n",
       " 'America West has ordered 15 PW6124 powered A318s.',\n",
       " 'The CFM56-5A3 engine is rated at 26,500 lbs thrust.',\n",
       " 'About $1,260.',\n",
       " 'Although its sales performance is disappointing, it still exceeds that of the 737-600.',\n",
       " 'Several inspections and modifications were introduced to address corrosion in gear attachment areas and lower wing skins.',\n",
       " 'The PW6000 engines have been selected for 30 aircraft.',\n",
       " 'It utilizes an onboard fault detection and analysis system and transmits fault messages to ground stations.',\n",
       " 'The maximum gross weight is 169,750 lbs (77.0 tonnes).',\n",
       " 'The A320 family is powered by CFM56-5A, CFM56-5B, and V.2500 engines.',\n",
       " 'About 660 MH annually.',\n",
       " 'Major operators include Air Canada (45) and Air France (55).',\n",
       " 'Additional costs include about $50,000 for soft-time components and $60,000 for cabin refurbishment materials.',\n",
       " 'From 2007.',\n",
       " 'Major -A1 operators include America West (24) and Indian Airlines (47).',\n",
       " 'Around 520 MH per year.',\n",
       " 'There are 27 A319s, 18 A320s, and four A321s listed in storage.',\n",
       " 'Variants of maximum take-off weight (MTOW) and different fuel capacity options.',\n",
       " 'The high-pressure compressor LLPs have lives of 18,200 EFC for engines powering the A319 and A320.',\n",
       " 'Mandatory inspections were introduced to detect and address water ingress issues.',\n",
       " 'The A320 family replaced BAC 1-11s, Caravelles, F.28s, and Tu-134s/-154s.',\n",
       " 'About 180 MH per year.',\n",
       " 'The maximum seating capacity is 164 seats.',\n",
       " 'Chafing marks on engine suction lines caused by incorrectly installed struts.',\n",
       " 'The CMV for a 2003 A318 is approximately $25.75 million.',\n",
       " 'About 3.0 MH for routine and non-routine work combined.',\n",
       " 'Large customers include jetBlue (173), United Airlines (117), and Air Asia (60).',\n",
       " 'They share a standard six-abreast economy class configuration.',\n",
       " 'The A319 accommodates 124 seats in a two-class configuration.',\n",
       " 'The V.2522-A5 has 36 orders, including 23 for United Airlines.',\n",
       " 'The extended range is 2,600 nm.',\n",
       " 'The reserve cost for the CFM56-5B is approximately $56 per EFH.',\n",
       " 'The A320 family had 4,283 orders, while the 737NG had 2,967 orders.',\n",
       " \"The A319's sales volume is comparable, with 1,239 orders against 1,260 for the 727-200 and 1,113 for the 737-300.\",\n",
       " 'A 2005 A321-200 can realize a lease rate of $369,000-$409,000.',\n",
       " 'Only 18 aircraft are equipped with CFM56-5B1 engines.',\n",
       " 'Engine selections were outstanding for about 380 aircraft.',\n",
       " 'CFDS receives system failure messages, displays them on the ECAM, and sends them to the MCDU and maintenance control via ACARS.',\n",
       " 'Ratings between 25,000lbs and 27,000lbs.',\n",
       " 'The CMV of a 1997 A320 is $24.9 million, with values decreasing by $1.3 million for each year of age.',\n",
       " 'Cracking due to non-metallic inclusions in the sliding tube base metal.',\n",
       " 'A 2000 A319 should attract a rental of $231,000-$253,000.',\n",
       " 'The fuel capacity is 4,185 US Gallons (USG).',\n",
       " '7,040 US gallons.',\n",
       " 'The options are 141,100 lbs, 149,920 lbs, 154,330 lbs, and 166,450 lbs.',\n",
       " 'The average time consumed for routine inspection is about 0.5 MH, with additional time for non-routine work.',\n",
       " 'Approximately 1,250 MH annually.',\n",
       " 'The A320 received a total of 2,428 firm orders.',\n",
       " 'The current backlog exceeds 1,650 units.',\n",
       " 'The labor cost for A checks is about $36,500 per year.',\n",
       " 'The MTOW variants are 162,050 lbs (73.5 tonnes), 166,450 lbs (75.5 tonnes), and 169,750 lbs (77.0 tonnes).',\n",
       " 'There were 918 orders for the A320 family in 2005.',\n",
       " 'ECAM displays system failure messages and is part of the fault detection and analysis system on the A320.',\n",
       " 'The MTOW of the A320-200 is 162,040 lbs (73.5 tonnes).',\n",
       " 'The CMV for a 2005 A319 is approximately $38 million.',\n",
       " 'The A320 was the first aircraft launched in the family.',\n",
       " 'It can be tailored for individual customers, improving fuel efficiency and reducing maintenance costs.',\n",
       " '1.2% more fuel.',\n",
       " 'The thrust ratings range from 23,000 lbs to 32,000 lbs.',\n",
       " 'The fuel capacity is 6,300 USG.',\n",
       " 'The A319 can utilize both CFM56-5A and -5B engines.',\n",
       " 'First shop visit costs range from $800,000 to $920,000, depending on engine rating.',\n",
       " 'Rotable support includes leasing homebase stock and accessing serviceable units on an exchange basis.',\n",
       " 'The A321 was developed following large sales of the 757 in the 1980s.',\n",
       " 'The V.2500-A5 series had an increased fan width and higher core flow for higher thrust ratings.',\n",
       " 'The aircraft can be powered by CFM56-5A or -5B engines, V.2500-A1 or -A5 engines, and PW6000 engines for the A318.',\n",
       " 'The A321 has a standard two-class capacity of 185 seats.',\n",
       " 'The largest orders have been placed by easyJet (140) and ILFC (150).',\n",
       " 'The A318 has been seen as a niche type, but sales have increased due to the A318 Elite corporate jet.',\n",
       " 'The A318 utilizes the CFM56-5B series and PW6000 series engines.',\n",
       " 'They have a common pilot type rating.',\n",
       " 'A free retrofit with a new magnetic variation table to avoid autoland issues at some airports.',\n",
       " 'A brand-new A320 entering a five-year lease should have a rental in the $357,000-$395,000 range.',\n",
       " 'The CFM56-5B4, which burned 11.4% more fuel than the V.2500-A1.',\n",
       " 'LLPs are generally replaced at every second shop visit and every 15,000 EFC.',\n",
       " 'The ratings are V.2530-A5 (30,400 lbs) and V.2533-A5 (33,000 lbs).',\n",
       " 'The CFM56-5B series.',\n",
       " 'The total capacity can be increased to 7,066 USG.',\n",
       " 'An additional high-pressure compressor (HPC) stage was added.',\n",
       " 'Recent US airline bankruptcies have made additional aircraft available.',\n",
       " '766 aircraft are powered by CFM56-5B4 engines.',\n",
       " 'More than 110 A319s powered by the V.2522-A5 have been built.',\n",
       " 'Thrust ratings range from 21,600 to 32,000 lbs across nine variants.',\n",
       " 'The A321 is the most fuel-efficient family member in terms of fuel burn per seat.',\n",
       " 'The CMV of a 1997, early-production A321-200 is about $22.5 million.',\n",
       " 'Only 19 A320-100 series aircraft were ordered.',\n",
       " 'Aircraft with higher MTOW may burn the same amount of fuel as lower-weight variants equipped with the same engines.',\n",
       " 'TR checks are performed about 1,480 times a year.',\n",
       " 'There are five MTOW variants for the A321.',\n",
       " 'The CFM56-5B and V.2500-A5 series engines.',\n",
       " 'The total annual cost for pre-flight checks is about $14,000.',\n",
       " 'Maintenance costs can vary based on the engine type, operational conditions, and maintenance intervals.',\n",
       " 'The V.2524-A5 engine.']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset['answers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hamna/miniconda3/envs/loggpt/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': dataset_text_field. Will not be supported from version '0.13.0'.\n",
      "\n",
      "Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/home/hamna/miniconda3/envs/loggpt/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:309: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n",
      "  warnings.warn(\n",
      "/home/hamna/miniconda3/envs/loggpt/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:328: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.9094, 'grad_norm': 0.5839182138442993, 'learning_rate': 8.064516129032258e-05, 'epoch': 0.49019607843137253}\n",
      "{'loss': 2.3989, 'grad_norm': 0.5574783086776733, 'learning_rate': 0.00016129032258064516, 'epoch': 0.9803921568627451}\n",
      "{'loss': 1.4803, 'grad_norm': 0.7125798463821411, 'learning_rate': 0.00019997868484717502, 'epoch': 1.4705882352941178}\n",
      "{'loss': 1.2866, 'grad_norm': 0.5978853702545166, 'learning_rate': 0.0001998179240714399, 'epoch': 1.9607843137254903}\n",
      "{'loss': 1.2407, 'grad_norm': 0.7319638133049011, 'learning_rate': 0.0001994998089790829, 'epoch': 2.450980392156863}\n",
      "{'loss': 1.1452, 'grad_norm': 0.7047911286354065, 'learning_rate': 0.00019902484105100974, 'epoch': 2.9411764705882355}\n",
      "{'loss': 1.0632, 'grad_norm': 0.6869220733642578, 'learning_rate': 0.0001983937690330437, 'epoch': 3.431372549019608}\n",
      "{'loss': 1.0632, 'grad_norm': 0.700506329536438, 'learning_rate': 0.00019760758775559274, 'epoch': 3.9215686274509802}\n",
      "{'loss': 0.978, 'grad_norm': 0.6509790420532227, 'learning_rate': 0.00019666753656538544, 'epoch': 4.411764705882353}\n",
      "{'loss': 0.9726, 'grad_norm': 0.7228720784187317, 'learning_rate': 0.00019557509737174828, 'epoch': 4.901960784313726}\n",
      "{'loss': 0.8825, 'grad_norm': 1.1729475259780884, 'learning_rate': 0.00019433199231050368, 'epoch': 5.392156862745098}\n",
      "{'loss': 0.8723, 'grad_norm': 0.8396925926208496, 'learning_rate': 0.00019294018102917207, 'epoch': 5.882352941176471}\n",
      "{'loss': 0.8094, 'grad_norm': 1.1131635904312134, 'learning_rate': 0.00019140185759775717, 'epoch': 6.372549019607844}\n",
      "{'loss': 0.7794, 'grad_norm': 1.1764061450958252, 'learning_rate': 0.0001897194470499846, 'epoch': 6.862745098039216}\n",
      "{'loss': 0.7134, 'grad_norm': 1.0558652877807617, 'learning_rate': 0.0001878956015604461, 'epoch': 7.352941176470588}\n",
      "{'loss': 0.721, 'grad_norm': 1.2052421569824219, 'learning_rate': 0.00018593319626367588, 'epoch': 7.8431372549019605}\n",
      "{'loss': 0.7082, 'grad_norm': 1.0130587816238403, 'learning_rate': 0.00018383532472174987, 'epoch': 8.333333333333334}\n",
      "{'loss': 0.6546, 'grad_norm': 1.6886937618255615, 'learning_rate': 0.000181605294047553, 'epoch': 8.823529411764707}\n",
      "{'loss': 0.5897, 'grad_norm': 0.940588653087616, 'learning_rate': 0.0001792466196914019, 'epoch': 9.313725490196079}\n",
      "{'loss': 0.6036, 'grad_norm': 1.0700267553329468, 'learning_rate': 0.00017676301989924187, 'epoch': 9.803921568627452}\n",
      "{'loss': 0.5599, 'grad_norm': 0.8972724080085754, 'learning_rate': 0.00017415840985115396, 'epoch': 10.294117647058824}\n",
      "{'loss': 0.5567, 'grad_norm': 1.2281773090362549, 'learning_rate': 0.00017143689548941254, 'epoch': 10.784313725490197}\n",
      "{'loss': 0.5373, 'grad_norm': 1.338365912437439, 'learning_rate': 0.00016860276704582265, 'epoch': 11.27450980392157}\n",
      "{'loss': 0.5136, 'grad_norm': 1.6382914781570435, 'learning_rate': 0.00016566049227854107, 'epoch': 11.764705882352942}\n",
      "{'loss': 0.5137, 'grad_norm': 1.8630400896072388, 'learning_rate': 0.00016261470942904223, 'epoch': 12.254901960784313}\n",
      "{'loss': 0.4836, 'grad_norm': 1.3764605522155762, 'learning_rate': 0.00015947021991033204, 'epoch': 12.745098039215687}\n",
      "{'loss': 0.482, 'grad_norm': 0.9145065546035767, 'learning_rate': 0.000156231980737936, 'epoch': 13.235294117647058}\n",
      "{'loss': 0.4573, 'grad_norm': 1.2143211364746094, 'learning_rate': 0.00015290509671559314, 'epoch': 13.72549019607843}\n",
      "{'loss': 0.4512, 'grad_norm': 0.8820605874061584, 'learning_rate': 0.0001494948123879751, 'epoch': 14.215686274509803}\n",
      "{'loss': 0.4082, 'grad_norm': 0.7217736840248108, 'learning_rate': 0.00014600650377311522, 'epoch': 14.705882352941176}\n",
      "{'loss': 0.3454, 'grad_norm': 0.8326200246810913, 'learning_rate': 0.00014244566988758152, 'epoch': 15.196078431372548}\n",
      "{'loss': 0.2677, 'grad_norm': 0.7845990657806396, 'learning_rate': 0.00013881792407775318, 'epoch': 15.686274509803921}\n",
      "{'loss': 0.2399, 'grad_norm': 0.3253602981567383, 'learning_rate': 0.0001351289851708658, 'epoch': 16.176470588235293}\n",
      "{'loss': 0.1983, 'grad_norm': 0.6343995928764343, 'learning_rate': 0.00013138466845977542, 'epoch': 16.666666666666668}\n",
      "{'loss': 0.1853, 'grad_norm': 0.5433765053749084, 'learning_rate': 0.00012759087653565256, 'epoch': 17.15686274509804}\n",
      "{'loss': 0.1625, 'grad_norm': 0.9106341600418091, 'learning_rate': 0.00012375358998305839, 'epoch': 17.647058823529413}\n",
      "{'loss': 0.1546, 'grad_norm': 0.2937222421169281, 'learning_rate': 0.00011987885795207076, 'epoch': 18.137254901960784}\n",
      "{'loss': 0.1463, 'grad_norm': 0.4875965714454651, 'learning_rate': 0.0001159727886223227, 'epoch': 18.627450980392158}\n",
      "{'loss': 0.1469, 'grad_norm': 0.45049968361854553, 'learning_rate': 0.00011204153957398611, 'epoch': 19.11764705882353}\n",
      "{'loss': 0.1381, 'grad_norm': 0.8742548823356628, 'learning_rate': 0.00010809130808087955, 'epoch': 19.607843137254903}\n",
      "{'loss': 0.1457, 'grad_norm': 0.574921727180481, 'learning_rate': 0.00010412832134100257, 'epoch': 20.098039215686274}\n",
      "{'loss': 0.1287, 'grad_norm': 1.1475920677185059, 'learning_rate': 0.00010015882665989704, 'epoch': 20.58823529411765}\n",
      "{'loss': 0.1366, 'grad_norm': 0.35889890789985657, 'learning_rate': 9.618908160231095e-05, 'epoch': 21.07843137254902}\n",
      "{'loss': 0.1284, 'grad_norm': 0.3333575427532196, 'learning_rate': 9.2225344127689e-05, 'epoch': 21.568627450980394}\n",
      "{'loss': 0.1347, 'grad_norm': 0.3321513831615448, 'learning_rate': 8.82738627250415e-05, 'epoch': 22.058823529411764}\n",
      "{'loss': 0.1225, 'grad_norm': 0.3790660500526428, 'learning_rate': 8.434086656274216e-05, 'epoch': 22.54901960784314}\n",
      "{'loss': 0.1296, 'grad_norm': 0.4765067994594574, 'learning_rate': 8.043255566878341e-05, 'epoch': 23.03921568627451}\n",
      "{'loss': 0.1216, 'grad_norm': 0.29935768246650696, 'learning_rate': 7.65550911569692e-05, 'epoch': 23.529411764705884}\n",
      "{'loss': 0.1257, 'grad_norm': 0.25695693492889404, 'learning_rate': 7.271458551445198e-05, 'epoch': 24.019607843137255}\n",
      "{'loss': 0.1178, 'grad_norm': 0.34354034066200256, 'learning_rate': 6.891709296592623e-05, 'epoch': 24.509803921568626}\n",
      "{'loss': 0.1274, 'grad_norm': 0.5902499556541443, 'learning_rate': 6.516859992966711e-05, 'epoch': 25.0}\n",
      "{'loss': 0.1143, 'grad_norm': 0.4022357165813446, 'learning_rate': 6.147501558046028e-05, 'epoch': 25.49019607843137}\n",
      "{'loss': 0.1199, 'grad_norm': 0.25220510363578796, 'learning_rate': 5.7842162534299414e-05, 'epoch': 25.980392156862745}\n",
      "{'loss': 0.1135, 'grad_norm': 0.5194976925849915, 'learning_rate': 5.4275767669536146e-05, 'epoch': 26.470588235294116}\n",
      "{'loss': 0.1187, 'grad_norm': 0.49140796065330505, 'learning_rate': 5.0781453098952e-05, 'epoch': 26.96078431372549}\n",
      "{'loss': 0.1126, 'grad_norm': 0.4883718192577362, 'learning_rate': 4.7364727306984355e-05, 'epoch': 27.45098039215686}\n",
      "{'loss': 0.1169, 'grad_norm': 0.5177395343780518, 'learning_rate': 4.403097646607745e-05, 'epoch': 27.941176470588236}\n",
      "{'loss': 0.109, 'grad_norm': 0.27692699432373047, 'learning_rate': 4.078545594584789e-05, 'epoch': 28.431372549019606}\n",
      "{'loss': 0.1145, 'grad_norm': 0.3331720232963562, 'learning_rate': 3.76332820284494e-05, 'epoch': 28.92156862745098}\n",
      "{'loss': 0.1089, 'grad_norm': 0.31801533699035645, 'learning_rate': 3.457942384319672e-05, 'epoch': 29.41176470588235}\n",
      "{'loss': 0.1129, 'grad_norm': 0.2956708073616028, 'learning_rate': 3.162869553316358e-05, 'epoch': 29.901960784313726}\n",
      "{'loss': 0.1079, 'grad_norm': 0.2693415880203247, 'learning_rate': 2.8785748666102775e-05, 'epoch': 30.392156862745097}\n",
      "{'loss': 0.111, 'grad_norm': 0.31856104731559753, 'learning_rate': 2.6055064901652327e-05, 'epoch': 30.88235294117647}\n",
      "{'loss': 0.1084, 'grad_norm': 0.3238205909729004, 'learning_rate': 2.3440948926386886e-05, 'epoch': 31.372549019607842}\n",
      "{'loss': 0.1102, 'grad_norm': 0.2926673889160156, 'learning_rate': 2.0947521667852177e-05, 'epoch': 31.862745098039216}\n",
      "{'loss': 0.1069, 'grad_norm': 0.28809744119644165, 'learning_rate': 1.8578713798279246e-05, 'epoch': 32.35294117647059}\n",
      "{'loss': 0.1078, 'grad_norm': 0.31258317828178406, 'learning_rate': 1.6338259538220114e-05, 'epoch': 32.84313725490196}\n",
      "{'loss': 0.1075, 'grad_norm': 0.26274803280830383, 'learning_rate': 1.4229690769872216e-05, 'epoch': 33.333333333333336}\n",
      "{'loss': 0.1066, 'grad_norm': 0.32237061858177185, 'learning_rate': 1.2256331469371928e-05, 'epoch': 33.8235294117647}\n",
      "{'loss': 0.1051, 'grad_norm': 0.26583659648895264, 'learning_rate': 1.0421292466833865e-05, 'epoch': 34.31372549019608}\n",
      "{'loss': 0.1052, 'grad_norm': 0.3191559910774231, 'learning_rate': 8.727466542396478e-06, 'epoch': 34.80392156862745}\n",
      "{'loss': 0.1068, 'grad_norm': 0.26952940225601196, 'learning_rate': 7.177523866004687e-06, 'epoch': 35.294117647058826}\n",
      "{'loss': 0.1049, 'grad_norm': 0.31778067350387573, 'learning_rate': 5.77390778811796e-06, 'epoch': 35.78431372549019}\n",
      "{'loss': 0.1063, 'grad_norm': 0.2553669214248657, 'learning_rate': 4.518830987979961e-06, 'epoch': 36.27450980392157}\n",
      "{'loss': 0.1037, 'grad_norm': 0.3132323622703552, 'learning_rate': 3.4142719855211226e-06, 'epoch': 36.76470588235294}\n",
      "{'loss': 0.1049, 'grad_norm': 0.30062010884284973, 'learning_rate': 2.4619720223934106e-06, 'epoch': 37.254901960784316}\n",
      "{'loss': 0.1028, 'grad_norm': 0.29903411865234375, 'learning_rate': 1.6634323170533928e-06, 'epoch': 37.745098039215684}\n",
      "{'loss': 0.1057, 'grad_norm': 0.4802064299583435, 'learning_rate': 1.019911698221454e-06, 'epoch': 38.23529411764706}\n",
      "{'loss': 0.1022, 'grad_norm': 0.2845826745033264, 'learning_rate': 5.324246204472472e-07, 'epoch': 38.72549019607843}\n",
      "{'loss': 0.1048, 'grad_norm': 0.3341468274593353, 'learning_rate': 2.017395649098197e-07, 'epoch': 39.21568627450981}\n",
      "{'loss': 0.1041, 'grad_norm': 0.516661524772644, 'learning_rate': 2.8377827973713467e-08, 'epoch': 39.705882352941174}\n",
      "{'train_runtime': 823.9019, 'train_samples_per_second': 9.807, 'train_steps_per_second': 2.476, 'train_loss': 0.4236034050876019, 'epoch': 40.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2040, training_loss=0.4236034050876019, metrics={'train_runtime': 823.9019, 'train_samples_per_second': 9.807, 'train_steps_per_second': 2.476, 'train_loss': 0.4236034050876019, 'epoch': 40.0})"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading the Lora Configration\n",
    "# Load LoRA configuration\n",
    "peft_config = LoraConfig(\n",
    "    lora_alpha=lora_alpha,\n",
    "    lora_dropout=lora_dropout,\n",
    "    r=lora_r,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "#Setting the Training Parameters for model Training\n",
    "training_arguments = TrainingArguments(\n",
    "    output_dir = output_dir,\n",
    "    num_train_epochs = num_train_epochs,\n",
    "    per_device_train_batch_size = per_device_train_batch_size,\n",
    "    gradient_accumulation_steps = gradient_accumulation_steps, \n",
    "    optim = optim,\n",
    "    save_steps = save_steps,\n",
    "    logging_steps = logging_steps,\n",
    "    learning_rate = learning_rate,\n",
    "    weight_decay = weight_decay,\n",
    "    save_total_limit=5,\n",
    "    fp16 = fp16,\n",
    "    bf16=bf16,\n",
    "    max_grad_norm = max_grad_norm,\n",
    "    max_steps = max_steps,\n",
    "    warmup_ratio = warmup_ratio,\n",
    "    group_by_length = group_by_length,\n",
    "    lr_scheduler_type = lr_scheduler_type,\n",
    "    report_to = 'tensorboard'\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    train_dataset = train_dataset,\n",
    "    peft_config = peft_config,\n",
    "    dataset_text_field = \"prompt\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    tokenizer = tokenizer,\n",
    "    args = training_arguments,\n",
    "    packing = packing\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.model.save_pretrained(new_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'''python\n",
    "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 22 Nov 2024\\n\\n<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nHow are A checks structured under Revision 28 of the A320’s MPD?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nA checks are grouped as a generic check and typically performed every 450 FH.<|eot_id|><|start_header_id|>assistant<|end_header_id|>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>user<|end_header_id|>What is the range of seating capacities for the A320 family?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n"
     ]
    }
   ],
   "source": [
    "question = \"What is the range of seating capacities for the A320 family?\"\n",
    "\n",
    "prompt = (\n",
    "    \"<|begin_of_text|>\"                              # start of prompt\n",
    "    \"<|start_header_id|>user<|end_header_id|>\"       # user header\n",
    "    f\"{question}\"                                    # user input\n",
    "    \"<|eot_id|>\"                                     #end of turn\n",
    "    \"<|start_header_id|>assistant<|end_header_id|>\"  #assistant header\n",
    ")\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>user<|end_header_id|>What is the range of seating capacities for the A320 family?<|eot_id|><|start_header_id|>assistant<|end_header_id|>How many seats can the A320 family accommodate?\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Ignore warnings\n",
    "logging.set_verbosity(logging.CRITICAL)\n",
    "\n",
    "# Run text generation pipeline with our next model\n",
    "# prompt = \"What is a large language model?\"\n",
    "pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=200)\n",
    "result = pipe(prompt)\n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>user<|end_header_id|>What is the range of seating capacities for the A320 family?<|eot_id|><|start_header_id|>assistant<|end_header_id|>How many options are there for range?\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Ignore warnings\n",
    "logging.set_verbosity(logging.CRITICAL)\n",
    "\n",
    "# Run text generation pipeline with our next model\n",
    "# prompt = \"What is a large language model?\"\n",
    "pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=200)\n",
    "result = pipe(prompt)\n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del model\n",
    "del tokenizer\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 6            |        cudaMalloc retries: 6         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |  17895 MiB |  17895 MiB | 296269 GiB | 296251 GiB |\n",
      "|       from large pool |  17655 MiB |  17655 MiB | 294385 GiB | 294368 GiB |\n",
      "|       from small pool |    240 MiB |    240 MiB |   1883 GiB |   1882 GiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |  17895 MiB |  17895 MiB | 296269 GiB | 296251 GiB |\n",
      "|       from large pool |  17655 MiB |  17655 MiB | 294385 GiB | 294368 GiB |\n",
      "|       from small pool |    240 MiB |    240 MiB |   1883 GiB |   1882 GiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Requested memory      |  17839 MiB |  17839 MiB | 293872 GiB | 293855 GiB |\n",
      "|       from large pool |  17599 MiB |  17599 MiB | 291991 GiB | 291973 GiB |\n",
      "|       from small pool |    240 MiB |    240 MiB |   1881 GiB |   1881 GiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |  18018 MiB |  18018 MiB |  45046 MiB |  27028 MiB |\n",
      "|       from large pool |  17698 MiB |  17698 MiB |  44376 MiB |  26678 MiB |\n",
      "|       from small pool |    320 MiB |    320 MiB |    670 MiB |    350 MiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory | 125430 KiB | 125430 KiB | 200414 GiB | 200414 GiB |\n",
      "|       from large pool |  43712 KiB |  43712 KiB | 198428 GiB | 198428 GiB |\n",
      "|       from small pool |  81718 KiB |  81718 KiB |   1986 GiB |   1985 GiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |    2138    |    2138    |   32722 K  |   32720 K  |\n",
      "|       from large pool |     934    |     934    |   24110 K  |   24109 K  |\n",
      "|       from small pool |    1204    |    1204    |    8612 K  |    8611 K  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |    2138    |    2138    |   32722 K  |   32720 K  |\n",
      "|       from large pool |     934    |     934    |   24110 K  |   24109 K  |\n",
      "|       from small pool |    1204    |    1204    |    8612 K  |    8611 K  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |     644    |     644    |    1537    |     893    |\n",
      "|       from large pool |     484    |     484    |    1202    |     718    |\n",
      "|       from small pool |     160    |     160    |     335    |     175    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |     148    |     148    |   16986 K  |   16985 K  |\n",
      "|       from large pool |      19    |      19    |   13264 K  |   13263 K  |\n",
      "|       from small pool |     129    |     129    |    3722 K  |    3721 K  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.memory_summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.reset_peak_memory_stats()\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA peak memory stats reset.\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.reset_peak_memory_stats()\n",
    "print(\"CUDA peak memory stats reset.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Nov 28 11:18:27 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.120                Driver Version: 550.120        CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3090        Off |   00000000:65:00.0  On |                  N/A |\n",
      "| 53%   36C    P2            155W /  390W |   24028MiB /  24576MiB |     15%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      1970      G   /usr/lib/xorg/Xorg                           1681MiB |\n",
      "|    0   N/A  N/A      2108      G   /usr/bin/gnome-shell                          177MiB |\n",
      "|    0   N/A  N/A      3460      G   ...seed-version=20241121-182614.093000        233MiB |\n",
      "|    0   N/A  N/A      5591      G   ...nglingPtr --variations-seed-version        320MiB |\n",
      "|    0   N/A  N/A      5962      G   ...erProcess --variations-seed-version        414MiB |\n",
      "|    0   N/A  N/A      7633      C   ...a/miniconda3/envs/loggpt/bin/python       2830MiB |\n",
      "|    0   N/A  N/A     10894      C   ...a/miniconda3/envs/loggpt/bin/python      18340MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.11s/it]\n"
     ]
    }
   ],
   "source": [
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    low_cpu_mem_usage=True,\n",
    "    return_dict=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=device_map,\n",
    ")\n",
    "model = PeftModel.from_pretrained(base_model, new_model)\n",
    "model = model.merge_and_unload()\n",
    "\n",
    "# Reload tokenizer to save it\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.model.save_pretrained('/media/hamna/New Volume/pdf_fine_tune_llama_work/fine_tune_llama_32_3b_pdf/fine_tune_model_weights_60epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import locale\n",
    "locale.getpreferredencoding = lambda: \"UTF-8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 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"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local wegiths saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and tokenizer saved locally in fine_tune_32_3b_model_40_qa_custom_1\n"
     ]
    }
   ],
   "source": [
    "# Define the directory where you want to save the model and tokenizer\n",
    "local_dir = \"fine_tune_32_3b_model_40_qa_custom_1\"\n",
    "\n",
    "# Save the model locally\n",
    "model.save_pretrained(local_dir)\n",
    "\n",
    "# Save the tokenizer locally\n",
    "tokenizer.save_pretrained(local_dir)\n",
    "\n",
    "print(f\"Model and tokenizer saved locally in {local_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model-00002-of-00002.safetensors:   0%|          | 0.00/1.46G [00:00<?, ?B/s]\n",
      "model-00002-of-00002.safetensors: 100%|██████████| 1.46G/1.46G [10:15<00:00, 2.37MB/s] \n",
      "\n",
      "model-00001-of-00002.safetensors: 100%|██████████| 4.97G/4.97G [25:05<00:00, 3.30MB/s]\n",
      "\n",
      "Upload 2 LFS files: 100%|██████████| 2/2 [25:05<00:00, 752.94s/it]\n",
      "tokenizer.json: 100%|██████████| 17.2M/17.2M [00:08<00:00, 1.99MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/Hassan883/llama_32_3b_fine_tune_model_50epoch_1/commit/c24181ea42d796f37fde14e9b1398698ea149e40', commit_message='Upload tokenizer', commit_description='', oid='c24181ea42d796f37fde14e9b1398698ea149e40', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.push_to_hub(\"Hassan883/llama_32_3b_fine_tune_model_50epoch_1\", check_pr=True)\n",
    "\n",
    "# tokenizer.push_to_hub(\"Hassan883/llama_32_3b_fine_tune_model_50epoch_1\",check_pr=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inferencing on finetuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unused kwargs: ['bnb_4bit_computer_dtype']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========\n",
      " Your GPU supports bfloat16: accelearate training with bf16=True\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.34it/s]\n"
     ]
    }
   ],
   "source": [
    "model_name = 'fine_tune_32_3b_model_40_qa_custom_1'\n",
    "compute_dtype = getattr(torch, bnb_4bit_compute_dtype)\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit = use_4bit,\n",
    "    bnb_4bit_quant_type = bnb_4bit_quant_type,\n",
    "    bnb_4bit_computer_dtype = compute_dtype,\n",
    "    bnb_4bit_use_double_quant = use_nested_quant\n",
    ")\n",
    "\n",
    "if compute_dtype == torch.float16 and use_4bit:\n",
    "    major, _ = torch.cuda.get_device_capability()\n",
    "    if major >= 8:\n",
    "        print(\"=\" * 8)\n",
    "        print(\" Your GPU supports bfloat16: accelearate training with bf16=True\")\n",
    "        print(\"=\" * 80)\n",
    "\n",
    "#Loading the base Model\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config  =  bnb_config,\n",
    "    device_map = device_map\n",
    ")\n",
    "\n",
    "model.config.use_cache = False\n",
    "model.config.pretraining_tp = 1\n",
    "\n",
    "#Now Loading the Llama Model architecture Tokenizier\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>user<|end_header_id|>What is the range of seating capacities for the A320 family?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n"
     ]
    }
   ],
   "source": [
    "question = \"What is the range of seating capacities for the A320 family?\"\n",
    "\n",
    "prompt = (\n",
    "    \"<|begin_of_text|>\"                              # start of prompt\n",
    "    \"<|start_header_id|>user<|end_header_id|>\"       # user header\n",
    "    f\"{question}\"                                    # user input\n",
    "    \"<|eot_id|>\"                                     #end of turn\n",
    "    \"<|start_header_id|>assistant<|end_header_id|>\"  #assistant header\n",
    ")\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Ignore warnings\n",
    "logging.set_verbosity(logging.CRITICAL)\n",
    "\n",
    "# Run text generation pipeline with our next model\n",
    "# prompt = \"What is a large language model?\"\n",
    "def inference_func(model, tokenizer,prompt, max_seq_length=200):\n",
    "    pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=max_seq_length)\n",
    "    result = pipe(prompt)\n",
    "    print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_template_func(question):\n",
    "    question = question\n",
    "\n",
    "    prompt = (\n",
    "        \"<|begin_of_text|>\"                              # start of prompt\n",
    "        \"<|start_header_id|>user<|end_header_id|>\"       # user header\n",
    "        f\"{question}\"                                    # user input\n",
    "        \"<|eot_id|>\"                                     #end of turn\n",
    "        \"<|start_header_id|>assistant<|end_header_id|>\"  #assistant header\n",
    "    )\n",
    "\n",
    "    print(prompt)\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hamna/miniconda3/envs/loggpt/lib/python3.10/site-packages/bitsandbytes/nn/modules.py:452: UserWarning: Input type into Linear4bit is torch.float16, but bnb_4bit_compute_dtype=torch.float32 (default). This will lead to slow inference or training speed.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>user<|end_header_id|>What is the range of seating capacities for the A320 family?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The range is from 107 to 185 seats.\n"
     ]
    }
   ],
   "source": [
    "inference_func(model=model,tokenizer=tokenizer, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['questions', 'answers', 'prompt'],\n",
       "    num_rows: 23\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What thrust ratings are available for the CFM56-5B engines on the A321?',\n",
       " 'How are post-flight technical logs maintained?',\n",
       " 'How many MH are typically consumed during a C8 check?',\n",
       " 'How does the A321’s seating capacity compare to the 737-900ER?',\n",
       " 'When is the detailed engineering work for future freighter conversions expected to begin?',\n",
       " 'What problem was detected in the A320 elevators related to water ingress?',\n",
       " 'What thrust ratings are available for the V.2500-A5 engines on the A319?',\n",
       " 'What are the fuel capacities available for the A321 with supplementary tanks?',\n",
       " 'What flight control system is featured in the A320 family?',\n",
       " 'What was the route used to analyze fuel burn performance?',\n",
       " 'What is the role of the full authority digital engine control (FADEC) system?',\n",
       " 'What is the first step in the process of clearing technical defects?',\n",
       " 'What is the objective of the enhanced ground proximity warning system (EGPWS) modification?',\n",
       " 'What is the annual cost for materials during daily checks?',\n",
       " 'What are the three categories of modification programs available for the A320 family?',\n",
       " 'How many total orders had the A320 family received by the end of 2005?',\n",
       " 'How does the A320 family reduce operating costs?',\n",
       " 'How many MTOW variants does the A321 have?',\n",
       " 'What are the maintenance costs for heavy components like wheels and brakes?',\n",
       " 'What is the average cost for materials and consumables for weekly checks?',\n",
       " 'What is the maintenance cost per flight hour for line and ramp checks?',\n",
       " 'What is the range of seating capacities for the A320 family?',\n",
       " 'How has the perception of A319 values changed compared to A320s?']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset['questions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The thrust ratings include -5B4 (27,000 lbs), -5B1 (30,000 lbs), -5B2 (31,000 lbs), and -5B3 (33,000 lbs).',\n",
       " 'Flight crew log ECAM messages in the post-flight technical log.',\n",
       " 'A C8 check can consume around 20,000 MH, including various tasks.',\n",
       " 'The A321 has five more seats than the 737-900ER.',\n",
       " 'In 2008.',\n",
       " 'Cracks in the honeycomb panels due to fatigue.',\n",
       " 'The thrust ratings are V.2522-A5 (22,000 lbs), V.2524-A5 (23,500 lbs), and V.2527-A5 (26,500 lbs).',\n",
       " 'The total capacities are 7,040 USG and 7,800 USG.',\n",
       " 'The A320 family features a fly-by-wire (FBW) flight control system.',\n",
       " 'The London Heathrow to Munich route.',\n",
       " 'It allows for easy changes to thrust ratings, with each having a different list price.',\n",
       " 'Logging and troubleshooting the defects.',\n",
       " 'To provide a direct link to GPS to avoid false warnings caused by position shifts.',\n",
       " 'About $125,000.',\n",
       " 'Engine upgrades, avionics, and future passenger-to-freighter conversions.',\n",
       " 'The A320 family received 4,283 orders by the end of 2005.',\n",
       " 'It provides high commonality in flightcrew and maintenance-related costs.',\n",
       " 'Up to five different MTOW variants.',\n",
       " 'The maintenance costs total approximately $180 per flight cycle (FC) for all heavy components.',\n",
       " 'Approximately $42,000 per year.',\n",
       " 'The total annual cost for line and ramp checks is $595,000, equating to a rate of $212 per flight hour (FH).',\n",
       " 'The A320 family offers models with seating capacities ranging from 107 to 185 seats.',\n",
       " 'A319 values fell less during downturns and have remained more stable than A320 values.']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset['answers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>user<|end_header_id|>How often are TR checks typically performed for the A320?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n"
     ]
    }
   ],
   "source": [
    "question = 'How often are TR checks typically performed for the A320?'\n",
    "\n",
    "prompt = prompt_template_func(question=question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>user<|end_header_id|>How often are TR checks typically performed for the A320?<|eot_id|><|start_header_id|>assistant<|end_header_id|>How often are inspection cycles performed for the A320?\n"
     ]
    }
   ],
   "source": [
    "inference_func(model=model, tokenizer=tokenizer, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "from transformers import pipeline\n",
    "import logging\n",
    "import re\n",
    "# from datasets import load_metric\n",
    "# Function for inference\n",
    "def inference_func(model, tokenizer, prompt, max_seq_length=200):\n",
    "    pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=max_seq_length)\n",
    "    result = pipe(prompt)\n",
    "    return result[0]['generated_text']\n",
    "\n",
    "# Function to preprocess test dataset\n",
    "def preprocess_prompt(question):\n",
    "    prompt = (\n",
    "        \"<|begin_of_text|>\"                               # Start of prompt\n",
    "        \"<|start_header_id|>system<|end_header_id|>\\n\\n\"  # System role\n",
    "        \"Please answer the question factually and concisely.\\n\\n\"  # Instruction\n",
    "        \"<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\n\"  # User header\n",
    "        f\"{question}\\n\\n\"                                 # User input\n",
    "        \"<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n\"  # Assistant header\n",
    "    )\n",
    "    return prompt\n",
    "\n",
    "\n",
    "# Load test dataset (Replace 'your_test_dataset' with your actual dataset)\n",
    "# test_dataset = Dataset.from_dict({\n",
    "#     \"questions\": [\n",
    "#         \"What engines are available for the A318?\",\n",
    "#         \"What is the first step in the process of clearing technical defects?\",\n",
    "#         # Add other test questions here...\n",
    "#     ],\n",
    "#     \"answers\": [\n",
    "#         \"The A318 utilizes the CFM56-5B series and the PW6000 series.\",\n",
    "#         \"Logging and troubleshooting the defects.\",\n",
    "#         # Add corresponding ground truth answers here...\n",
    "#     ]\n",
    "# })\n",
    "\n",
    "# Evaluate the model on the test dataset\n",
    "# Load F1 metric\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Casting the dataset: 100%|██████████| 23/23 [00:00<00:00, 5714.31 examples/s]\n",
      "Casting the dataset: 100%|██████████| 23/23 [00:00<00:00, 5503.39 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: TR checks are typically performed every 5-6 months. (<class 'str'>), Reference: TR checks are performed about 1,480 times a year. (<class 'str'>)\n",
      "Prediction: There are 97 A320s powered by CFM56-5B4 engines. (<class 'str'>), Reference: 766 aircraft are powered by CFM56-5B4 engines. (<class 'str'>)\n",
      "Prediction: The A320 family has delivered over 1,700 aircraft until now. (<class 'str'>), Reference: More than 2,600 aircraft have been delivered. (<class 'str'>)\n",
      "Prediction: The A318 received 95 orders, while the 737-600 received 127. (<class 'str'>), Reference: The A318's performance, while disappointing, still exceeds that of the 737-600. (<class 'str'>)\n",
      "Prediction: The supplementary fuel tanks increase the total capacity to 7,000 USG. (<class 'str'>), Reference: The total capacity can be increased to 7,066 USG. (<class 'str'>)\n",
      "Prediction: Approximately 180 MH annually. (<class 'str'>), Reference: Around 520 MH per year. (<class 'str'>)\n",
      "Prediction: The CFM56-5B and V.2500-A5 series engines. (<class 'str'>), Reference: The aircraft can be powered by CFM56-5A or -5B engines, V.2500-A1 or -A5 engines, and PW6000 engines for the A318. (<class 'str'>)\n",
      "Prediction: The large lateral doors. (<class 'str'>), Reference: They share a standard six-abreast economy class configuration. (<class 'str'>)\n",
      "Prediction: About 360 MH. (<class 'str'>), Reference: A C8 check can consume around 20,000 MH, including various tasks. (<class 'str'>)\n",
      "Prediction: Enhanced digital displays and increased storage. (<class 'str'>), Reference: A free retrofit with a new magnetic variation table to avoid autoland issues at some airports. (<class 'str'>)\n",
      "Prediction: The A319 has 145 orders on hand. (<class 'str'>), Reference: A total of 492 A319s are on order. (<class 'str'>)\n",
      "Prediction: The A320 family received a total of 2,428 orders. (<class 'str'>), Reference: The A320 family received 4,283 orders by the end of 2005. (<class 'str'>)\n",
      "Prediction: To accommodate large cargo racks and modify the freight capacity. (<class 'str'>), Reference: To address cracks and fatigue issues around rivets and fittings in the fuselage and landing gear areas. (<class 'str'>)\n",
      "Prediction: 2-1-1. (<class 'str'>), Reference: The A320 typically has 12 first-class and 138 economy seats. (<class 'str'>)\n",
      "Prediction: There were 23 engines outstanding, which were due for modification. (<class 'str'>), Reference: Engine selections were outstanding for about 380 aircraft. (<class 'str'>)\n",
      "Prediction: The A318 utilizes the CFM56-5B series and PW6000 series engines. (<class 'str'>), Reference: The A318 utilizes the CFM56-5B series and the PW6000 series. (<class 'str'>)\n",
      "Prediction: Commercial Pilot Airline (CPA) rating. (<class 'str'>), Reference: They have a common pilot type rating. (<class 'str'>)\n",
      "Prediction: Five orders for the A319. (<class 'str'>), Reference: The V.2524-A5 has 113 orders for the A319. (<class 'str'>)\n",
      "Prediction: Approximately $4,500. (<class 'str'>), Reference: The total annual cost for line and ramp checks is $595,000, equating to a rate of $212 per flight hour (FH). (<class 'str'>)\n",
      "Prediction: 1.2% more fuel. (<class 'str'>), Reference: 6.1-6.5% more fuel. (<class 'str'>)\n",
      "Prediction: 19 aircraft. (<class 'str'>), Reference: Only 19 A320-100 series aircraft were ordered. (<class 'str'>)\n",
      "Prediction: It saves about 15 kilometers of range. (<class 'str'>), Reference: It increases the tracked distance to 628 nautical miles and flight time to 90-92 minutes. (<class 'str'>)\n",
      "Prediction: It shares components, uses the same engine type, and allows for standardization of software and future upgrades. (<class 'str'>), Reference: It provides high commonality in flightcrew and maintenance-related costs. (<class 'str'>)\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset, Value\n",
    "from transformers import pipeline, AutoTokenizer\n",
    "import logging\n",
    "import re\n",
    "import evaluate\n",
    "\n",
    "# Function for inference\n",
    "def inference_func(model, tokenizer, prompt, max_seq_length=200):\n",
    "    pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=max_seq_length)\n",
    "    result = pipe(prompt)\n",
    "    return result[0]['generated_text']\n",
    "\n",
    "# Function to preprocess test dataset\n",
    "def preprocess_prompt(question):\n",
    "    prompt = (\n",
    "        \"<|begin_of_text|>\"                               # Start of prompt\n",
    "        \"<|start_header_id|>system<|end_header_id|>\\n\\n\"  # System role\n",
    "        \"Please answer the question factually and concisely.\\n\\n\"  # Instruction\n",
    "        \"<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\n\"  # User header\n",
    "        f\"{question}\\n\\n\"                                 # User input\n",
    "        \"<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n\"  # Assistant header\n",
    "    )\n",
    "    return prompt\n",
    "\n",
    "# F1 metric\n",
    "f1_metric = evaluate.load(\"f1\")\n",
    "\n",
    "# Normalize function for consistent string comparison\n",
    "def normalize_answer(answer):\n",
    "    \"\"\"Normalize text for fair comparison.\"\"\"\n",
    "    if not isinstance(answer, str):\n",
    "        answer = str(answer)  # Convert non-string types to strings\n",
    "    answer = answer.lower().strip()\n",
    "    answer = re.sub(r\"[^a-z0-9\\s]\", \"\", answer)  # Remove special characters\n",
    "    answer = re.sub(r\"\\s+\", \" \", answer)        # Normalize spaces\n",
    "    return answer\n",
    "\n",
    "# Function to clean and validate the dataset\n",
    "def clean_dataset(dataset):\n",
    "    \"\"\"Ensure all entries in the dataset are strings.\"\"\"\n",
    "    cleaned_questions = []\n",
    "    cleaned_answers = []\n",
    "    for question, answer in zip(dataset[\"questions\"], dataset[\"answers\"]):\n",
    "        if not isinstance(question, str):\n",
    "            question = str(question)  # Convert to string if not already\n",
    "        if not isinstance(answer, str):\n",
    "            answer = str(answer)  # Convert to string if not already\n",
    "        cleaned_questions.append(question.strip())\n",
    "        cleaned_answers.append(answer.strip())\n",
    "    return Dataset.from_dict({\"questions\": cleaned_questions, \"answers\": cleaned_answers})\n",
    "\n",
    "# Updated evaluation function\n",
    "def evaluate_model_with_f1(model, tokenizer, test_dataset):\n",
    "    predictions = []\n",
    "    references = []\n",
    "    \n",
    "    for example in test_dataset:\n",
    "        # Prepare the prompt\n",
    "        prompt = preprocess_prompt(example[\"questions\"])\n",
    "\n",
    "        # Generate the model's prediction\n",
    "        generated_text = inference_func(model, tokenizer, prompt, max_seq_length=200)\n",
    "\n",
    "        # Extract and clean prediction\n",
    "        response_start = \"<|start_header_id|>assistant<|end_header_id|>\"\n",
    "        if response_start in generated_text:\n",
    "            prediction = generated_text.split(response_start, 1)[1].strip()\n",
    "        else:\n",
    "            prediction = generated_text.strip()\n",
    "\n",
    "        predictions.append(prediction)\n",
    "        references.append(example[\"answers\"])\n",
    "\n",
    "    # Validate data types\n",
    "    for pred, ref in zip(predictions, references):\n",
    "        print(f\"Prediction: {pred} ({type(pred)}), Reference: {ref} ({type(ref)})\")\n",
    "\n",
    "test_dataset = clean_dataset(test_dataset)\n",
    "\n",
    "# Ensure dataset columns are properly typed\n",
    "test_dataset_t = test_dataset.cast_column(\"questions\", Value(\"string\"))\n",
    "test_dataset_t = test_dataset.cast_column(\"answers\", Value(\"string\"))\n",
    "\n",
    "# Example usage (Replace `model` and `tokenizer` with your fine-tuned LLaMA model and tokenizer)\n",
    "# from transformers import AutoModelForCausalLM\n",
    "# model = AutoModelForCausalLM.from_pretrained(\"your_model_path\")\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"your_model_path\")\n",
    "\n",
    "# Run evaluation\n",
    "evaluate_model_with_f1(model, tokenizer, test_dataset_t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Casting the dataset:   0%|          | 0/23 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Casting the dataset: 100%|██████████| 23/23 [00:00<00:00, 5256.02 examples/s]\n",
      "Casting the dataset: 100%|██████████| 23/23 [00:00<00:00, 7572.73 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1: What thrust ratings are available for the CFM56-5B engines on the A321?\n",
      "Generated Answer: The available thrust ratings are 25,000 lbs. (11.4 kN) and 27,000 lbs. (12.1 kN).\n",
      "Expected Answer: The thrust ratings include -5B4 (27,000 lbs), -5B1 (30,000 lbs), -5B2 (31,000 lbs), and -5B3 (33,000 lbs).\n",
      "------------------------------\n",
      "Q2: How are post-flight technical logs maintained?\n",
      "Generated Answer: Post-flight technical logs are typically maintained on the flight’s maintenance record.\n",
      "Expected Answer: Flight crew log ECAM messages in the post-flight technical log.\n",
      "------------------------------\n",
      "Q3: How many MH are typically consumed during a C8 check?\n",
      "Generated Answer: Six MH.\n",
      "Expected Answer: A C8 check can consume around 20,000 MH, including various tasks.\n",
      "------------------------------\n",
      "Q4: How does the A321’s seating capacity compare to the 737-900ER?\n",
      "Generated Answer: The A321’s two-class seating capacity is 185 versus 177 for the 737-900ER.\n",
      "Expected Answer: The A321 has five more seats than the 737-900ER.\n",
      "------------------------------\n",
      "Q5: When is the detailed engineering work for future freighter conversions expected to begin?\n",
      "Generated Answer: After March 2007.\n",
      "Expected Answer: In 2008.\n",
      "------------------------------\n",
      "Q6: What problem was detected in the A320 elevators related to water ingress?\n",
      "Generated Answer: How often does unauthorized access occur?\n",
      "Expected Answer: Cracks in the honeycomb panels due to fatigue.\n",
      "------------------------------\n",
      "Q7: What thrust ratings are available for the V.2500-A5 engines on the A319?\n",
      "Generated Answer: The available thrust ratings are V.2530-A5 (30,400 lbs) and V.2533-A5 (33,000 lbs).\n",
      "Expected Answer: The thrust ratings are V.2522-A5 (22,000 lbs), V.2524-A5 (23,500 lbs), and V.2527-A5 (26,500 lbs).\n",
      "------------------------------\n",
      "Q8: What are the fuel capacities available for the A321 with supplementary tanks?\n",
      "Generated Answer: The available fuel capacities are 6,300 litres, 6,810 litres, and 7,110 litres.\n",
      "Expected Answer: The total capacities are 7,040 USG and 7,800 USG.\n",
      "------------------------------\n",
      "Q9: What flight control system is featured in the A320 family?\n",
      "Generated Answer: Flight Debye system.\n",
      "Expected Answer: The A320 family features a fly-by-wire (FBW) flight control system.\n",
      "------------------------------\n",
      "Q10: What was the route used to analyze fuel burn performance?\n",
      "Generated Answer: The routes used were London (LHR) to Paris (PFH) and back to LHR.\n",
      "Expected Answer: The London Heathrow to Munich route.\n",
      "------------------------------\n",
      "Q11: What is the role of the full authority digital engine control (FADEC) system?\n",
      "Generated Answer: It provides a standard interface for aircraft and engine components.\n",
      "Expected Answer: It allows for easy changes to thrust ratings, with each having a different list price.\n",
      "------------------------------\n",
      "Q12: What is the first step in the process of clearing technical defects?\n",
      "Generated Answer: Inspecting the flight data recorder (FDR) and automatic flight recorder (AFR).\n",
      "Expected Answer: Logging and troubleshooting the defects.\n",
      "------------------------------\n",
      "Q13: What is the objective of the enhanced ground proximity warning system (EGPWS) modification?\n",
      "Generated Answer: To avoid flying into mountains by missing identified warning zones (IAZWs).\n",
      "Expected Answer: To provide a direct link to GPS to avoid false warnings caused by position shifts.\n",
      "------------------------------\n",
      "Q14: What is the annual cost for materials during daily checks?\n",
      "Generated Answer: About $1,250.\n",
      "Expected Answer: About $125,000.\n",
      "------------------------------\n",
      "Q15: What are the three categories of modification programs available for the A320 family?\n",
      "Generated Answer: Maintenance programs, technical modification programs, and field programs.\n",
      "Expected Answer: Engine upgrades, avionics, and future passenger-to-freighter conversions.\n",
      "------------------------------\n",
      "Q16: How many total orders had the A320 family received by the end of 2005?\n",
      "Generated Answer: The A320 family had 928 total orders by the end of 2005.\n",
      "Expected Answer: The A320 family received 4,283 orders by the end of 2005.\n",
      "------------------------------\n",
      "Q17: How does the A320 family reduce operating costs?\n",
      "Generated Answer: It allows for cost-effective utilization of staff and machinery, shares resources among operators, and allows for income from lease payments.\n",
      "Expected Answer: It provides high commonality in flightcrew and maintenance-related costs.\n",
      "------------------------------\n",
      "Q18: How many MTOW variants does the A321 have?\n",
      "Generated Answer: Four MTOW variants.\n",
      "Expected Answer: Up to five different MTOW variants.\n",
      "------------------------------\n",
      "Q19: What are the maintenance costs for heavy components like wheels and brakes?\n",
      "Generated Answer: About $15,000 for an individual wheel and $20,000 for a brake unit.\n",
      "Expected Answer: The maintenance costs total approximately $180 per flight cycle (FC) for all heavy components.\n",
      "------------------------------\n",
      "Q20: What is the average cost for materials and consumables for weekly checks?\n",
      "Generated Answer: About $1,250.\n",
      "Expected Answer: Approximately $42,000 per year.\n",
      "------------------------------\n",
      "Q21: What is the maintenance cost per flight hour for line and ramp checks?\n",
      "Generated Answer: About $1,450.\n",
      "Expected Answer: The total annual cost for line and ramp checks is $595,000, equating to a rate of $212 per flight hour (FH).\n",
      "------------------------------\n",
      "Q22: What is the range of seating capacities for the A320 family?\n",
      "Generated Answer: 12-54 seats.\n",
      "Expected Answer: The A320 family offers models with seating capacities ranging from 107 to 185 seats.\n",
      "------------------------------\n",
      "Q23: How has the perception of A319 values changed compared to A320s?\n",
      "Generated Answer: How has perception of A319 values compared to A320s? A319 values have improved by at least $20 million in residual values.\n",
      "Expected Answer: A319 values fell less during downturns and have remained more stable than A320 values.\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset, Value\n",
    "from transformers import pipeline, AutoTokenizer\n",
    "import re\n",
    "import evaluate\n",
    "\n",
    "# Function for inference\n",
    "def inference_func(model, tokenizer, prompt, max_seq_length=200):\n",
    "    \"\"\"Generate text using the model and tokenizer.\"\"\"\n",
    "    pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=max_seq_length)\n",
    "    result = pipe(prompt)\n",
    "    return result[0]['generated_text']\n",
    "\n",
    "# Function to preprocess a question into the desired prompt format\n",
    "def preprocess_prompt(question):\n",
    "    \"\"\"Format a question into the desired prompt template.\"\"\"\n",
    "    prompt = (\n",
    "        \"<|begin_of_text|>\"                               # Start of prompt\n",
    "        \"<|start_header_id|>system<|end_header_id|>\\n\\n\"  # System role\n",
    "        \"Please answer the question factually and concisely.\\n\\n\"  # Instruction\n",
    "        \"<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\n\"  # User header\n",
    "        f\"{question}\\n\\n\"                                 # User input\n",
    "        \"<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n\"  # Assistant header\n",
    "    )\n",
    "    return prompt\n",
    "\n",
    "# Normalize function for consistent string comparison\n",
    "def normalize_answer(answer):\n",
    "    \"\"\"Normalize text for fair comparison.\"\"\"\n",
    "    if not isinstance(answer, str):\n",
    "        answer = str(answer)  # Convert non-string types to strings\n",
    "    answer = answer.lower().strip()\n",
    "    answer = re.sub(r\"[^a-z0-9\\s]\", \"\", answer)  # Remove special characters\n",
    "    answer = re.sub(r\"\\s+\", \" \", answer)        # Normalize spaces\n",
    "    return answer\n",
    "\n",
    "# Function to clean and validate the dataset\n",
    "def clean_dataset(dataset):\n",
    "    \"\"\"Ensure all entries in the dataset are strings.\"\"\"\n",
    "    cleaned_questions = []\n",
    "    cleaned_answers = []\n",
    "    for question, answer in zip(dataset[\"questions\"], dataset[\"answers\"]):\n",
    "        if not isinstance(question, str):\n",
    "            question = str(question)  # Convert to string if not already\n",
    "        if not isinstance(answer, str):\n",
    "            answer = str(answer)  # Convert to string if not already\n",
    "        cleaned_questions.append(question.strip())\n",
    "        cleaned_answers.append(answer.strip())\n",
    "    return Dataset.from_dict({\"questions\": cleaned_questions, \"answers\": cleaned_answers})\n",
    "\n",
    "# Updated inference function to handle unknown answers\n",
    "def inference_with_default_response(model, tokenizer, question, max_seq_length=200):\n",
    "    \"\"\"Generate a response and return 'Sorry, I don't know' if the model does not provide a valid answer.\"\"\"\n",
    "    prompt = preprocess_prompt(question)\n",
    "    generated_text = inference_func(model, tokenizer, prompt, max_seq_length=max_seq_length)\n",
    "\n",
    "    # Extract the assistant's response\n",
    "    response_start = \"<|start_header_id|>assistant<|end_header_id|>\"\n",
    "    if response_start in generated_text:\n",
    "        prediction = generated_text.split(response_start, 1)[1].strip()\n",
    "    else:\n",
    "        prediction = generated_text.strip()\n",
    "\n",
    "    # Handle cases where the model cannot generate a response\n",
    "    if not prediction or prediction.lower() in [\"i don't know\", \"i am not sure\", \"\"]:\n",
    "        return \"Sorry, I don't know.\"\n",
    "    return prediction\n",
    "\n",
    "# # Example Dataset (Replace this with your actual dataset)\n",
    "# test_dataset = Dataset.from_dict({\n",
    "#     \"questions\": [\n",
    "#         \"What engines are available for the A318?\",\n",
    "#         \"What is the first step in the process of clearing technical defects?\",\n",
    "#         \"How long is the wingspan of the A320?\",\n",
    "#         \"What is the purpose of life?\"  # Example for a question the model might not know\n",
    "#     ],\n",
    "#     \"answers\": [\n",
    "#         \"The A318 utilizes the CFM56-5B series and the PW6000 series.\",\n",
    "#         \"Logging and troubleshooting the defects.\",\n",
    "#         \"The wingspan of the A320 is approximately 34.1 meters.\",\n",
    "#         \"Sorry, I don't know.\"\n",
    "#     ],\n",
    "# })\n",
    "\n",
    "# Clean and validate dataset\n",
    "test_dataset = clean_dataset(test_dataset)\n",
    "\n",
    "# Ensure dataset columns are properly typed\n",
    "test_dataset = test_dataset.cast_column(\"questions\", Value(\"string\"))\n",
    "test_dataset = test_dataset.cast_column(\"answers\", Value(\"string\"))\n",
    "\n",
    "# # Example usage (Replace `model` and `tokenizer` with your fine-tuned LLaMA model and tokenizer)\n",
    "# from transformers import AutoModelForCausalLM\n",
    "# model = AutoModelForCausalLM.from_pretrained(\"your_model_path\")\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"your_model_path\")\n",
    "\n",
    "# Testing the model on questions\n",
    "for idx, example in enumerate(test_dataset):\n",
    "    question = example[\"questions\"]\n",
    "    expected_answer = example[\"answers\"]\n",
    "    generated_answer = inference_with_default_response(model, tokenizer, question)\n",
    "    print(f\"Q{idx+1}: {question}\")\n",
    "    print(f\"Generated Answer: {generated_answer}\")\n",
    "    print(f\"Expected Answer: {expected_answer}\")\n",
    "    print(\"-\" * 30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "loggpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
